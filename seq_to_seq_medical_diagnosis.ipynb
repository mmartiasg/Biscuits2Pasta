{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import Seqtoseq.Transformers as transformers\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load medical dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Need to rework this dataset format\n",
    "\n",
    "In the translation is using a python array with each element being a tuple instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_source = []\n",
    "diagnosis_target = []\n",
    "classes = []\n",
    "\n",
    "with open(\"./datasets_diagnosis_extra/train.dat\") as f:\n",
    "    for line in f:\n",
    "        diagnosis_class, diagnosis_text = line.split(maxsplit=1)\n",
    "        diagnosis_source.append(diagnosis_text)\n",
    "        diagnosis_target.append(\"[start] \"+diagnosis_text+\" [end]\")\n",
    "        classes.append(int(diagnosis_class)-1)\n",
    "\n",
    "diagnosis_source = np.expand_dims(np.array(diagnosis_source), axis=1)\n",
    "diagnosis_target = np.expand_dims(np.array(diagnosis_target), axis=1)\n",
    "classes = np.expand_dims(np.array(classes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14438, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14438, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if they are equal\n",
    "\n",
    "for i in range(diagnosis_target.shape[0]):\n",
    "    assert diagnosis_source[i] == \" \".join(diagnosis_target[i][0].split(\" \")[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). \\n'],\n",
       "      dtype='<U4000')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[start] Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). \\n [end]'],\n",
       "      dtype='<U4014')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_target[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder / decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_TOKENS = 15000\n",
    "MAX_SEQ = 20\n",
    "\n",
    "EMBEDDING_SIZE = 256\n",
    "LATENT_DIM = 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "Seq to seq model \n",
    "\n",
    "Source -> Target\n",
    "\n",
    "Source == Target autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_return_state_simple = tf.keras.layers.LSTM(units=5, return_state=True)\n",
    "lstm_return_state_bidierectional_merge = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5, return_state=True), merge_mode=\"sum\")\n",
    "lstm_return_state_bidierectional_merge_non_state = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=5))\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(units=5, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleinput = np.expand_dims(np.expand_dims(np.array([1.0, 2.0, 3.0, 4.0]), axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.32210338,  0.05109679, -0.3413462 , -0.13140883, -0.03864373]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.32210338,  0.05109679, -0.3413462 , -0.13140883, -0.03864373]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.8631031 ,  0.05448556, -0.61244166, -0.2646039 , -0.05587917]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_return_state_simple(sampleinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.13813052, -0.6800886 , -0.6354073 , -0.09979478, -0.02149884]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.17677137, -0.61797935, -0.10627368, -0.14333901, -0.01797345]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.3110677 , -0.8732613 , -0.20648508, -0.5294663 , -0.29356617]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.03864086, -0.06210923, -0.5291336 ,  0.04354423, -0.0035254 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[ 0.07005788, -0.5513493 , -0.7270263 ,  0.29491407, -0.04881385]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_return_state_bidierectional_merge(sampleinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[ 0.13406432,  0.11476917, -0.07515836,  0.0324094 , -0.00403054,\n",
       "        -0.01870262,  0.01584945,  0.0606403 , -0.35255352,  0.01614536]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_return_state_bidierectional_merge_non_state(sampleinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "source = tf.keras.layers.Input(shape=(None, ), dtype=\"int64\", name=\"source\")\n",
    "\n",
    "# ENCODER START\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=MAX_TOKENS, output_dim=EMBEDDING_SIZE, mask_zero=True)(source)\n",
    "encoded_source = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=LATENT_DIM), merge_mode=\"sum\")(embeddings)\n",
    "# encoded_source = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LATENT_DIM), merge_mode=\"sum\")(embeddings)\n",
    "# A full sentence is reduce to the last state of a LSTM\n",
    "# ENCODER END\n",
    "\n",
    "# DECODER\n",
    "# Encodded token and new generated token as inputs\n",
    "# Reverse process like the conv1DTranspose with the segmentation model\n",
    "target = tf.keras.layers.Input(shape=(None, ), dtype=\"int64\", name=\"target\")\n",
    "\n",
    "#learn a representation from the target (Vocabsize, latent_dim)\n",
    "#Should this be MAX_TOKENS+1 for the END?\n",
    "latent_space = tf.keras.layers.Embedding(input_dim=MAX_TOKENS, output_dim=EMBEDDING_SIZE, mask_zero=True)(target)\n",
    "\n",
    "#This will return (TARGET_SHAPE, LATENT_DIM)\n",
    "# decoder = tf.keras.layers.LSTM(units=LATENT_DIM, return_sequences=True)\n",
    "decoder = tf.keras.layers.GRU(units=LATENT_DIM, return_sequences=True)\n",
    "\n",
    "#TODO: FIX TO WORK WITH LSTM\n",
    "# decoded_sentence = decoder(latent_space, initial_state=[encoded_source[1], encoded_source[2]])\n",
    "# decoded_sentence = decoder(latent_space, initial_state=[encoded_source[0][0], encoded_source[0][1]])\n",
    "decoded_sentence = decoder(latent_space, initial_state=encoded_source)\n",
    "\n",
    "decoded_sentence = tf.keras.layers.Dropout(0.5)(decoded_sentence)\n",
    "\n",
    "target_next_step = tf.keras.layers.Dense(units=MAX_TOKENS, activation=\"softmax\")(decoded_sentence)\n",
    "# DECODER\n",
    "\n",
    "# CREATE MODEL ENCODER / DECODER\n",
    "encoder_decoder_model = tf.keras.Model(inputs=[source, target], outputs=[target_next_step])\n",
    "\n",
    "encoder_decoder_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4), metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " source (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " target (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    3840000     ['source[0][0]']                 \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    3840000     ['target[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 1024)        7876608     ['embedding[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, None, 1024)   3938304     ['embedding_1[0][0]',            \n",
      "                                                                  'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 1024)   0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 15000)  15375000    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,869,912\n",
      "Trainable params: 34,869,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def standarization_source(input_string):\n",
    "    strip_chars = string.punctuation\n",
    "    \n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    remove_puntuation = tf.strings.regex_replace(lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"[0-9]+[.,]?[0-9]*\", \"[NUMBER]\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"\\[NUMBER]%\", \"[NUMBER_PERCENTAGE]\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"\\-+\", \"\")\n",
    "\n",
    "    return remove_puntuation\n",
    "\n",
    "def standarization_target(input_string):\n",
    "    strip_chars = string.punctuation\n",
    "    strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "    strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    remove_puntuation = tf.strings.regex_replace(lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"[0-9]+[.,]?[0-9]*\", \"[NUMBER]\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"\\[NUMBER]%\", \"[NUMBER_PERCENTAGE]\")\n",
    "    remove_puntuation = tf.strings.regex_replace(remove_puntuation, \"\\-+\", \"\")\n",
    "\n",
    "    return remove_puntuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). \\n'],\n",
       "      dtype='<U4000')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[start] Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). \\n [end]'],\n",
       "      dtype='<U4014')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 14:18:20.340762: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "source_vectorizer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS, output_sequence_length=MAX_SEQ, output_mode=\"int\", standardize=standarization_source)\n",
    "\n",
    "# Target will have one more character since it we need to cut one token to let the model to guess the next one\n",
    "target_vectorizer = tf.keras.layers.TextVectorization(max_tokens=MAX_TOKENS, output_sequence_length=MAX_SEQ+1, output_mode=\"int\", standardize=standarization_target) \n",
    "\n",
    "source_vectorizer.adapt(diagnosis_source)\n",
    "target_vectorizer.adapt(diagnosis_target)\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vect = source_vectorizer(source)\n",
    "    target_vect = target_vectorizer(target)\n",
    "\n",
    "    return(\n",
    "        {\n",
    "            \"source\":source_vect,\n",
    "            # Remove the [end] token\n",
    "            # Target and source are the same\n",
    "            \"target\":target_vect[:, :-1]\n",
    "        }\n",
    "        #ignore [start] token and gets up to the [end] token\n",
    "        # Is one token ahead of target\n",
    "        ,target_vect[:, 1:]\n",
    "    )\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((diagnosis_source, diagnosis_target)).batch(256).map(format_dataset, num_parallel_calls=8).shuffle(512).prefetch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocabulary = target_vectorizer.get_vocabulary()\n",
    "source_vocabulary = source_vectorizer.get_vocabulary()\n",
    "\n",
    "# Use to decode the predicted next token\n",
    "target_ditionary_vocabulary = dict(zip(range(MAX_TOKENS), target_vocabulary))\n",
    "source_ditionary_vocabulary = dict(zip(range(MAX_TOKENS), source_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq_example =datapoint[0][\"source\"][0]\n",
    "\n",
    "target_seq_example = datapoint[0][\"target\"][0]\n",
    "\n",
    "target_next_token = datapoint[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endosonography of perianal and [UNK] fistula andor abscess in crohns disease [UNK] endosonography es was performed in [NUMBER] patients with'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([source_vocabulary[token.numpy()] for token in source_seq_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] endosonography of perianal and [UNK] fistula andor abscess in crohns disease [UNK] endosonography es was performed in [NUMBER] patients'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([target_ditionary_vocabulary[token.numpy()] for token in target_seq_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endosonography of perianal and [UNK] fistula andor abscess in crohns disease [UNK] endosonography es was performed in [NUMBER] patients with'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([target_ditionary_vocabulary[token.numpy()] for token in target_next_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs source shape: (256, 20)\n",
      "inputs target shape: (256, 20)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in dataset.take(1):\n",
    "    print(f\"inputs source shape: {inputs['source'].shape}\")\n",
    "    print(f\"inputs target shape: {inputs['target'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor=\"loss\", filepath=\"./model/medical_diagnosis_lstm\")\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 8.7271 - sparse_categorical_accuracy: 0.0550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 120s 2s/step - loss: 8.7271 - sparse_categorical_accuracy: 0.0550\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 6.9377 - sparse_categorical_accuracy: 0.0556"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 112s 2s/step - loss: 6.9377 - sparse_categorical_accuracy: 0.0556\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 6.8833 - sparse_categorical_accuracy: 0.0581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 117s 2s/step - loss: 6.8833 - sparse_categorical_accuracy: 0.0581\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 6.8536 - sparse_categorical_accuracy: 0.0599"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 103s 2s/step - loss: 6.8536 - sparse_categorical_accuracy: 0.0599\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - ETA: 0s - loss: 6.8307 - sparse_categorical_accuracy: 0.0619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/medical_diagnosis_lstm/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 104s 2s/step - loss: 6.8307 - sparse_categorical_accuracy: 0.0619\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    encoder_decoder_model.fit(dataset, epochs=5, callbacks=[checkpoint, early_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 14:27:41.705649: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.541446: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.675594: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.681649: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.693188: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.826844: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.833399: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:42.857659: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:43.349219: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:43.726480: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:43.733345: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:43.984897: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:43.991451: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.001289: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.007868: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.069024: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.094164: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.100795: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.151860: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.158308: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.220574: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.281209: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.287637: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.361327: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.367645: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.490606: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.497751: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.508006: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.513974: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.630114: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:44.636478: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.139484: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.146298: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.240924: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.247098: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.922044: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.928729: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.938677: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.972468: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.979148: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.989140: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-05-14 14:27:45.995444: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    encoder_decoder_model = tf.keras.models.load_model(\"./model/medical_diagnosis_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocabulary = target_vectorizer.get_vocabulary()\n",
    "\n",
    "# Use to decode the predicted next token\n",
    "ditionary_vocabulary = dict(zip(range(MAX_TOKENS), target_vocabulary))\n",
    "\n",
    "def decode_sequence(input_sequence):\n",
    "\n",
    "    # Initial tokens\n",
    "    tokenized_input_sentence = source_vectorizer([input_sequence])\n",
    "\n",
    "    # We start with start token\n",
    "    decoded_sentence = \"[start] \"+input_sequence\n",
    "\n",
    "    for i in range(MAX_SEQ):\n",
    "        tokenized_target_sentence = target_vectorizer([decoded_sentence])\n",
    "\n",
    "        next_token_predictions = encoder_decoder_model.predict([\n",
    "            tokenized_input_sentence, tokenized_target_sentence\n",
    "        ], verbose=0)\n",
    "        \n",
    "        # the output is [1, MAX_SEQ+1, MAX_TOKENS]\n",
    "        #This will give 1 value for [1, MAX_SEQ, 1] <- next token index decoded from the softmax\n",
    "        sample_token_index = np.argmax(next_token_predictions[0, i, :])\n",
    "\n",
    "        # find token for that decoded token index\n",
    "        sample_token = ditionary_vocabulary[sample_token_index]\n",
    "\n",
    "        #Append the new generated token\n",
    "        decoded_sentence += \" \"+sample_token\n",
    "\n",
    "        #Finish before running out of tokens in the max sequence if we found the [END] token\n",
    "        if sample_token == \"[end]\":\n",
    "            break\n",
    "    \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] The patient was feeling of of of of of of of the the the the the of of of of of the the the'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    decoded_cpu = decode_sequence(\"The patient was feeling\")\n",
    "\n",
    "decoded_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] The patient was feeling [UNK] of of of of of of of of of of the the the the the of of of of'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    decoded_gpu = decode_sequence(\"The patient was feeling\")\n",
    "\n",
    "decoded_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
